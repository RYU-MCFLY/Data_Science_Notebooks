{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tozanni/Data_Science_Notebooks/blob/main/CIFAR10_Autoencoder_CNN_BaselineReto_SinSolucion.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AVM7YqFuQdmQ"
      },
      "outputs": [],
      "source": [
        "import keras\n",
        "from keras.datasets import cifar10\n",
        "from keras.models import Sequential\n",
        "from keras import datasets, layers, models\n",
        "from keras.utils import np_utils\n",
        "from keras import regularizers\n",
        "from keras.layers import Dense, Dropout, BatchNormalization\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cargar el dataset cifar10 en un conjunto inicial de training (imagenes y labels) y test (imágenes y labels)"
      ],
      "metadata": {
        "id": "wIPvOkVEOxL4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train0, y_train0), (x_test0, y_test0) = datasets.cifar10.load_data()\n"
      ],
      "metadata": {
        "id": "URm8pbI0TzDE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jnNtIWM2QlYn"
      },
      "outputs": [],
      "source": [
        "# Creamos la lista de etiquetas CIFAR10\n",
        "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer',\n",
        "               'dog', 'frog', 'horse', 'ship', 'truck']"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Pre-procesamiento del dataset\n",
        "\n",
        "a. Convierte los pixeles de las imágenes del conjunto de train y test a tipo float\n",
        "\n",
        "b. Normaliza, dividiendo el valor de todos los pixeles por 255, ya que es el valor máximo de intensidad de cada pixel.\n",
        "\n",
        "c. Codifica las etiquetas y_train y y_test como one-hot utilizando la funcion to_categorical\n"
      ],
      "metadata": {
        "id": "67vriW48PtnF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rS8WKQk-Qrge"
      },
      "outputs": [],
      "source": [
        "# Convierte los pixeles de las imágenes del conjunto de train y test a tipo float\n",
        "\n",
        "# Normaliza, dividiendo el valor de todos los pixeles por 255, ya que es el valor máximo de intensidad de cada pixel.\n",
        "\n",
        "# Codifica las etiquetas y_train y y_test como one-hot utilizando la funcion to_categorical\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dividimos el test set en 7000 imagenes de validacion (x_val_images) y 3000 de test set (x_test_images)\n"
      ],
      "metadata": {
        "id": "345zUigMP6-I"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wTkHv176aPmx"
      },
      "outputs": [],
      "source": [
        "# Dividir test en validacion y test, 7000 de validacion y 3000 de test\n",
        "x_val_images = x_test_images[:7000]\n",
        "x_test_images = x_test_images[7000:]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dividimos las etiquetas de validacion (y_val y y_test) de tal forma que correspondan a los conjuntos previos."
      ],
      "metadata": {
        "id": "fuQEuzYKQHtl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dividir etiquetas de validacion\n",
        "y_val_labels = y_test_labels[:7000]\n",
        "y_test_labels = y_test_labels[7000:]"
      ],
      "metadata": {
        "id": "wJCXIw32QLE7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Algunos imports complementarios\n",
        "from keras.layers import Input, Dense, Dropout, Activation, Add, Concatenate, Conv2D, Conv2DTranspose, UpSampling2D, MaxPooling2D, MaxPool2D, Flatten, BatchNormalization\n",
        "import keras.backend as K\n",
        "from keras.models import Model"
      ],
      "metadata": {
        "id": "pk-3fPqmQNkT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P3R55IXPXZCE"
      },
      "outputs": [],
      "source": [
        "# Modelo encoder-decoder de referencia\n",
        "\n",
        "input_img = Input(shape=(32, 32, 3))\n",
        "\n",
        "# Red encoder\n",
        "x = Conv2D(64, (3, 3), padding='same')(input_img)\n",
        "x = BatchNormalization()(x)\n",
        "x = Activation('relu')(x)\n",
        "x = MaxPooling2D((2, 2), padding='same')(x)\n",
        "\n",
        "x = Conv2D(32, (3, 3), padding='same')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Activation('relu')(x)\n",
        "x = MaxPooling2D((2, 2), padding='same')(x)\n",
        "\n",
        "x = Conv2D(16, (3, 3), padding='same')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Activation('relu')(x)\n",
        "encoded = MaxPooling2D((2, 2), padding='same')(x)\n",
        "\n",
        "# Red decoder\n",
        "x = Conv2D(16, (3, 3), padding='same')(encoded)\n",
        "x = BatchNormalization()(x)\n",
        "x = Activation('relu')(x)\n",
        "\n",
        "x = UpSampling2D((2, 2))(x)\n",
        "x = Conv2D(32, (3, 3), padding='same')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Activation('relu')(x)\n",
        "\n",
        "x = UpSampling2D((2, 2))(x)\n",
        "x = Conv2D(64, (3, 3), padding='same')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Activation('relu')(x)\n",
        "\n",
        "x = UpSampling2D((2, 2))(x)\n",
        "x = Conv2D(3, (3, 3), padding='same')(x)\n",
        "x = BatchNormalization()(x)\n",
        "decoded = Activation('sigmoid')(x)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "615q9rKZRbJu"
      },
      "outputs": [],
      "source": [
        "# Modelo Encoder-Decoder\n",
        "model = Model(input_img, decoded)\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy')\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Entrenamiento de autoencoder\n",
        "\n",
        "a. Entrena el modelo no-supervisado encoder-decoder de tal forma que el modelo aprenda a reconstruir su propio input, con batch_size 64, mínimo 20 épocas. \n",
        "\n",
        "b. Investiga e implementa el uso de los callbacks de EarlyStopping y ModelCheckpoint"
      ],
      "metadata": {
        "id": "0oAcGbsUEbys"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7nV8scCPQjkh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fge6U-PJWTRa"
      },
      "source": [
        "c. Visualización del proceso de entrenamiento. Grafica Training Loss vs. Validation Loss.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RVwViUKCQ9x3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7hzHkn23W2Sq"
      },
      "source": [
        "d. Visualización del input reconstruido\n",
        "\n",
        "Imprime un conjunto de imágenes originales y comparalas con la imagen reconstruida por el autoencoder. \n",
        "\n",
        "Utiliza las siguientes funciones de referencia."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xRWHe1haWKZg"
      },
      "outputs": [],
      "source": [
        "c10test = model.predict(x_test_images)\n",
        "c10val = model.predict(x_val_images)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9WTicX_pWyfp"
      },
      "outputs": [],
      "source": [
        "# Funcion para mostrar imagenes originales y reconstruidas\n",
        "\n",
        "def showOrigDec(orig, dec, num=10):\n",
        "    import matplotlib.pyplot as plt\n",
        "    n = num\n",
        "    plt.figure(figsize=(20, 4))\n",
        "\n",
        "    for i in range(n):\n",
        "        # original\n",
        "        ax = plt.subplot(2, n, i+1)\n",
        "        plt.imshow(orig[i].reshape(32, 32, 3))\n",
        "        ax.get_xaxis().set_visible(False)\n",
        "        ax.get_yaxis().set_visible(False)\n",
        "\n",
        "        # reconstruidas\n",
        "        ax = plt.subplot(2, n, i +1 + n)\n",
        "        plt.imshow(dec[i].reshape(32, 32, 3))\n",
        "        ax.get_xaxis().set_visible(False)\n",
        "        ax.get_yaxis().set_visible(False)\n",
        "    plt.show()\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Kc6xFbYYfj3"
      },
      "outputs": [],
      "source": [
        "# Muestra algunas imagenes originales y reconstruidas utilizando tu funcion\n",
        "#showOrigDec(x_test_images, c10test)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A continuación generaremos el modelo encoder del autoencoder. Este modelo lo utilizarás para obtener la representación codificada de los conjuntos originales y con ella entrenar un clasificador. "
      ],
      "metadata": {
        "id": "CQugJj1oSnr8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Modelo Encoder\n",
        "encoder = Model(input_img, encoded)\n",
        "encoder.summary()"
      ],
      "metadata": {
        "id": "YdNt44SYHIws"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Extracción de features del autoencoder\n",
        "\n",
        "Utilizando el **método predict del modelo encoder** extrae las variables que te indicamos a continuación: \n",
        "\n",
        "a. Codifica el el conjunto de imágenes de entrenamiento utilizando el método predict del encoder, y guárdalo en una variable llamada **gist_train_ae**\n",
        "\n",
        "b. Codifica el conjunto de imágenes de validación, utilizando el método predict del encoder y guárdalo en una variable llamada **gist_valid_ae**\n",
        "\n",
        "c. Codifica el conjunto de imágenes de prueba utilizando el método predict del encoder y guárdalo en una variable llamada **gist_test_ae**\n"
      ],
      "metadata": {
        "id": "IAta3hUdReZR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HcI-cTqQZGzT"
      },
      "outputs": [],
      "source": [
        "# Completa esta función...\n",
        "\n",
        "# gist_train_ae = \n",
        "# gist_valid_ae = \n",
        "# gist_test_ae = \n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A continuación definimos un clasificador con una capa convolucional y dos capas densas, que aprenderá a clasificar el input una vez procesado por el codificador. \n",
        "\n",
        "Puedes utilizar el siguiente clasificador como referencia:"
      ],
      "metadata": {
        "id": "7NyTrHuiJRmb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gntlowXWYjym"
      },
      "outputs": [],
      "source": [
        "input = Input((gist_train_ae.shape[1], gist_train_ae.shape[2], gist_train_ae.shape[3]))\n",
        "\n",
        "x = Conv2D(64, 3, padding=\"same\")(input)\n",
        "x = Activation('relu')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = MaxPool2D(2)(x)\n",
        "x = Dropout(0.5)(x)\n",
        "\n",
        "x = Flatten()(x)\n",
        "x = Dense(128, activation='relu')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Dropout(0.5)(x)\n",
        "\n",
        "output = Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "decoder_classifier = Model(input, output)\n",
        "decoder_classifier.compile(loss='categorical_crossentropy', optimizer=\"Adam\", metrics=['acc'])\n",
        "decoder_classifier.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yg0NF2GxZK-4"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Entrenamiento y evaluación del clasificador\n",
        "\n",
        "a. Entrena el clasificador **decoder_classifier** definido en la fase previa utilizando como input la representación codificada del training set obtenida en el paso previo y como output los labels originales del conjunto de training.\n",
        "\n",
        "b. Calcula la pérdida de validación del modelo, utilizando la representación codificada de los datos de validación y como ouput los labels originales del conjunto de validación.\n"
      ],
      "metadata": {
        "id": "LALau4YR6MXz"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dfyaKfN42W7U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "c. Genera predicciones con el modelo clasificador, utiliza el conjunto de test codificado modelo encoder. Guárdalo en la variable pred.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "hapDlY5xTL8-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Obtener las etiquetas con el clasificador\n",
        "#pred = \n",
        "# print(pred)\n",
        "\n",
        "# Convertimos las predicciones a una lista de etiquetas única\n",
        "pred_classes = np.argmax(pred, axis=1)\n",
        "print(pred_classes)\n"
      ],
      "metadata": {
        "id": "EVbIsCaB-_OR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "d. Evalúa las predicciones del modelo y obten la matriz de confusión."
      ],
      "metadata": {
        "id": "DIP23LYiR7an"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
        "\n",
        "cm=confusion_matrix(y_test_labels.argmax(axis=1), pred.argmax(axis=1))\n",
        "print(\"Classification Report:\\n\")\n",
        "cr=classification_report(y_test_labels.argmax(axis=1), pred.argmax(axis=1), target_names=class_names)\n",
        "print(cr)"
      ],
      "metadata": {
        "id": "cnhIsKSW8MA4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5. Mejoras a los modelos\n",
        "\n",
        "Aplicando los conceptos del curso modifica dichas redes para obtener un mejor accuracy ¿Crees poder lograr un 70% o tal vez 80% de accuracy con tu modelo? OJO: NO está permitido modificar el modelo clasificador. \n",
        "\n",
        "a.    Experimenta agregando capas, modificando operaciones y modificando las dimensiones de las capas actuales. OJO: Recuerda que para que tu modelo encoder-decoder siga funcionando y puedas reconstruir las imágenes codificadas, las capas de MaxPool del encoder deben de corresponder a las capas UpSample del decoder. Tip: ¿Las capas de pooling ayudan o perjudican a tu modelo?\n",
        "\n",
        " \n",
        "b.    En una celda de texto, justifica los cambios realizados, a la arquitectura.\n",
        " \n",
        "\n",
        "c.     Genera la matriz de confusión de tu ensamble de modelos mejorado. Recuerda que debes re-entrenar el clasificador si la arquitectura del autoencoder cambia. \n"
      ],
      "metadata": {
        "id": "SNfnSotBaTit"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EKhhpQjW-yyr"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": [],
      "authorship_tag": "ABX9TyNJjLyo87IFWk2DoUMyM4D9",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}