{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tozanni/Data_Science_Notebooks/blob/main/CIFAR10_Autoencoder_CNN_BaselineReto_SinSolucion.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AVM7YqFuQdmQ"
      },
      "outputs": [],
      "source": [
        "import keras\n",
        "from keras.datasets import cifar10\n",
        "from keras.models import Sequential\n",
        "from keras import datasets, layers, models\n",
        "from keras.utils import np_utils\n",
        "from keras import regularizers\n",
        "from keras.layers import Dense, Dropout, BatchNormalization\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cargar el dataset cifar10 en un conjunto inicial de training (imagenes y labels) y test (imágenes y labels)"
      ],
      "metadata": {
        "id": "wIPvOkVEOxL4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train0, y_train0), (x_test0, y_test0) = datasets.cifar10.load_data()\n"
      ],
      "metadata": {
        "id": "URm8pbI0TzDE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jnNtIWM2QlYn"
      },
      "outputs": [],
      "source": [
        "# Creamos la lista de etiquetas CIFAR10\n",
        "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer',\n",
        "               'dog', 'frog', 'horse', 'ship', 'truck']"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Pre-procesamiento del dataset\n",
        "\n",
        "a. Convierte los pixeles de las imágenes del conjunto de train y test a tipo float\n",
        "\n",
        "b. Normaliza, dividiendo el valor de todos los pixeles por 255, ya que es el valor máximo de intensidad de cada pixel.\n",
        "\n",
        "c. Codifica las etiquetas y_train y y_test como one-hot utilizando la funcion to_categorical\n"
      ],
      "metadata": {
        "id": "67vriW48PtnF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rS8WKQk-Qrge"
      },
      "outputs": [],
      "source": [
        "# Convierte los pixeles de las imágenes del conjunto de train y test a tipo float\n",
        "\n",
        "# Normaliza, dividiendo el valor de todos los pixeles por 255, ya que es el valor máximo de intensidad de cada pixel.\n",
        "\n",
        "# Codifica las etiquetas y_train y y_test como one-hot utilizando la funcion to_categorical\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dividimos el test set en 7000 imagenes de validacion (x_val_images) y 3000 de test set (x_test_images)\n"
      ],
      "metadata": {
        "id": "345zUigMP6-I"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wTkHv176aPmx"
      },
      "outputs": [],
      "source": [
        "# Dividir test en validacion y test, 7000 de validacion y 3000 de test\n",
        "x_val_images = x_test_images[:7000]\n",
        "x_test_images = x_test_images[7000:]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dividimos las etiquetas de validacion (y_val y y_test) de tal forma que correspondan a los conjuntos previos."
      ],
      "metadata": {
        "id": "fuQEuzYKQHtl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dividir etiquetas de validacion\n",
        "y_val_labels = y_test_labels[:7000]\n",
        "y_test_labels = y_test_labels[7000:]"
      ],
      "metadata": {
        "id": "wJCXIw32QLE7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Algunos imports complementarios\n",
        "from keras.layers import Input, Dense, Dropout, Activation, Add, Concatenate, Conv2D, Conv2DTranspose, UpSampling2D, MaxPooling2D, MaxPool2D, Flatten, BatchNormalization\n",
        "import keras.backend as K\n",
        "from keras.models import Model"
      ],
      "metadata": {
        "id": "pk-3fPqmQNkT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P3R55IXPXZCE"
      },
      "outputs": [],
      "source": [
        "# Modelo encoder-decoder de referencia\n",
        "\n",
        "input_img = Input(shape=(32, 32, 3))\n",
        "\n",
        "# Red encoder\n",
        "x = Conv2D(64, (3, 3), padding='same')(input_img)\n",
        "x = BatchNormalization()(x)\n",
        "x = Activation('relu')(x)\n",
        "x = MaxPooling2D((2, 2), padding='same')(x)\n",
        "\n",
        "x = Conv2D(32, (3, 3), padding='same')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Activation('relu')(x)\n",
        "x = MaxPooling2D((2, 2), padding='same')(x)\n",
        "\n",
        "x = Conv2D(16, (3, 3), padding='same')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Activation('relu')(x)\n",
        "encoded = MaxPooling2D((2, 2), padding='same')(x)\n",
        "\n",
        "# Red decoder\n",
        "x = Conv2D(16, (3, 3), padding='same')(encoded)\n",
        "x = BatchNormalization()(x)\n",
        "x = Activation('relu')(x)\n",
        "\n",
        "x = UpSampling2D((2, 2))(x)\n",
        "x = Conv2D(32, (3, 3), padding='same')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Activation('relu')(x)\n",
        "\n",
        "x = UpSampling2D((2, 2))(x)\n",
        "x = Conv2D(64, (3, 3), padding='same')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Activation('relu')(x)\n",
        "\n",
        "x = UpSampling2D((2, 2))(x)\n",
        "x = Conv2D(3, (3, 3), padding='same')(x)\n",
        "x = BatchNormalization()(x)\n",
        "decoded = Activation('sigmoid')(x)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "615q9rKZRbJu",
        "outputId": "07a712af-4d40-45b4-c692-dc6767deb26d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (None, 32, 32, 64)        1792      \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 32, 32, 64)       256       \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " activation (Activation)     (None, 32, 32, 64)        0         \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 16, 16, 64)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 16, 16, 32)        18464     \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 16, 16, 32)       128       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 16, 16, 32)        0         \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 8, 8, 32)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 8, 8, 16)          4624      \n",
            "                                                                 \n",
            " batch_normalization_2 (Batc  (None, 8, 8, 16)         64        \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation_2 (Activation)   (None, 8, 8, 16)          0         \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 4, 4, 16)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 4, 4, 16)          2320      \n",
            "                                                                 \n",
            " batch_normalization_3 (Batc  (None, 4, 4, 16)         64        \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation_3 (Activation)   (None, 4, 4, 16)          0         \n",
            "                                                                 \n",
            " up_sampling2d (UpSampling2D  (None, 8, 8, 16)         0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 8, 8, 32)          4640      \n",
            "                                                                 \n",
            " batch_normalization_4 (Batc  (None, 8, 8, 32)         128       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation_4 (Activation)   (None, 8, 8, 32)          0         \n",
            "                                                                 \n",
            " up_sampling2d_1 (UpSampling  (None, 16, 16, 32)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 16, 16, 64)        18496     \n",
            "                                                                 \n",
            " batch_normalization_5 (Batc  (None, 16, 16, 64)       256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation_5 (Activation)   (None, 16, 16, 64)        0         \n",
            "                                                                 \n",
            " up_sampling2d_2 (UpSampling  (None, 32, 32, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_6 (Conv2D)           (None, 32, 32, 3)         1731      \n",
            "                                                                 \n",
            " batch_normalization_6 (Batc  (None, 32, 32, 3)        12        \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation_6 (Activation)   (None, 32, 32, 3)         0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 52,975\n",
            "Trainable params: 52,521\n",
            "Non-trainable params: 454\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# Modelo Encoder-Decoder\n",
        "model = Model(input_img, decoded)\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy')\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Entrenamiento de autoencoder\n",
        "\n",
        "a. Entrena el modelo no-supervisado encoder-decoder de tal forma que el modelo aprenda a reconstruir su propio input, con batch_size 64, mínimo 20 épocas. \n",
        "\n",
        "b. Investiga e implementa el uso de los callbacks de EarlyStopping y ModelCheckpoint"
      ],
      "metadata": {
        "id": "0oAcGbsUEbys"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7nV8scCPQjkh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fge6U-PJWTRa"
      },
      "source": [
        "c. Visualización del proceso de entrenamiento. Grafica Training Loss vs. Validation Loss.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RVwViUKCQ9x3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7hzHkn23W2Sq"
      },
      "source": [
        "d. Visualización del input reconstruido\n",
        "\n",
        "Imprime un conjunto de imágenes originales y comparalas con la imagen reconstruida por el autoencoder. \n",
        "\n",
        "Utiliza las siguientes funciones de referencia."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xRWHe1haWKZg"
      },
      "outputs": [],
      "source": [
        "c10test = model.predict(x_test_images)\n",
        "c10val = model.predict(x_val_images)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9WTicX_pWyfp"
      },
      "outputs": [],
      "source": [
        "# Funcion para mostrar imagenes originales y reconstruidas\n",
        "\n",
        "def showOrigDec(orig, dec, num=10):\n",
        "    import matplotlib.pyplot as plt\n",
        "    n = num\n",
        "    plt.figure(figsize=(20, 4))\n",
        "\n",
        "    for i in range(n):\n",
        "        # original\n",
        "        ax = plt.subplot(2, n, i+1)\n",
        "        plt.imshow(orig[i].reshape(32, 32, 3))\n",
        "        ax.get_xaxis().set_visible(False)\n",
        "        ax.get_yaxis().set_visible(False)\n",
        "\n",
        "        # reconstruidas\n",
        "        ax = plt.subplot(2, n, i +1 + n)\n",
        "        plt.imshow(dec[i].reshape(32, 32, 3))\n",
        "        ax.get_xaxis().set_visible(False)\n",
        "        ax.get_yaxis().set_visible(False)\n",
        "    plt.show()\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Kc6xFbYYfj3"
      },
      "outputs": [],
      "source": [
        "# Muestra algunas imagenes originales y reconstruidas utilizando tu funcion\n",
        "#showOrigDec(x_test_images, c10test)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A continuación generaremos el modelo encoder del autoencoder. Este modelo lo utilizarás para obtener la representación codificada de los conjuntos originales y con ella entrenar un clasificador. "
      ],
      "metadata": {
        "id": "CQugJj1oSnr8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Modelo Encoder\n",
        "encoder = Model(input_img, encoded)\n",
        "encoder.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YdNt44SYHIws",
        "outputId": "c6d767bd-4bd3-4810-aef1-d08d370bf881"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (None, 32, 32, 64)        1792      \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 32, 32, 64)       256       \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " activation (Activation)     (None, 32, 32, 64)        0         \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 16, 16, 64)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 16, 16, 32)        18464     \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 16, 16, 32)       128       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 16, 16, 32)        0         \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 8, 8, 32)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 8, 8, 16)          4624      \n",
            "                                                                 \n",
            " batch_normalization_2 (Batc  (None, 8, 8, 16)         64        \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation_2 (Activation)   (None, 8, 8, 16)          0         \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 4, 4, 16)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 25,328\n",
            "Trainable params: 25,104\n",
            "Non-trainable params: 224\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Extracción de features del autoencoder\n",
        "\n",
        "Utilizando el **método predict del modelo encoder** extrae las variables que te indicamos a continuación: \n",
        "\n",
        "a. Codifica el el conjunto de imágenes de entrenamiento utilizando el método predict del encoder, y guárdalo en una variable llamada **gist_train_ae**\n",
        "\n",
        "b. Codifica el conjunto de imágenes de validación, utilizando el método predict del encoder y guárdalo en una variable llamada **gist_valid_ae**\n",
        "\n",
        "c. Codifica el conjunto de imágenes de prueba utilizando el método predict del encoder y guárdalo en una variable llamada **gist_test_ae**\n"
      ],
      "metadata": {
        "id": "IAta3hUdReZR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HcI-cTqQZGzT"
      },
      "outputs": [],
      "source": [
        "# Completa esta función...\n",
        "\n",
        "# gist_train_ae = \n",
        "# gist_valid_ae = \n",
        "# gist_test_ae = \n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A continuación definimos un clasificador con una capa convolucional y dos capas densas, que aprenderá a clasificar el input una vez procesado por el codificador. \n",
        "\n",
        "Puedes utilizar el siguiente clasificador como referencia:"
      ],
      "metadata": {
        "id": "7NyTrHuiJRmb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gntlowXWYjym",
        "outputId": "3f139298-df0f-4784-90dd-a8708a3ba313"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, 4, 4, 16)]        0         \n",
            "                                                                 \n",
            " conv2d_7 (Conv2D)           (None, 4, 4, 64)          9280      \n",
            "                                                                 \n",
            " activation_7 (Activation)   (None, 4, 4, 64)          0         \n",
            "                                                                 \n",
            " batch_normalization_7 (Batc  (None, 4, 4, 64)         256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPooling  (None, 2, 2, 64)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 2, 2, 64)          0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 256)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 128)               32896     \n",
            "                                                                 \n",
            " batch_normalization_8 (Batc  (None, 128)              512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 10)                1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 44,234\n",
            "Trainable params: 43,850\n",
            "Non-trainable params: 384\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "input = Input((gist_train_ae.shape[1], gist_train_ae.shape[2], gist_train_ae.shape[3]))\n",
        "\n",
        "x = Conv2D(64, 3, padding=\"same\")(input)\n",
        "x = Activation('relu')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = MaxPool2D(2)(x)\n",
        "x = Dropout(0.5)(x)\n",
        "\n",
        "x = Flatten()(x)\n",
        "x = Dense(128, activation='relu')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Dropout(0.5)(x)\n",
        "\n",
        "output = Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "decoder_classifier = Model(input, output)\n",
        "decoder_classifier.compile(loss='categorical_crossentropy', optimizer=\"Adam\", metrics=['acc'])\n",
        "decoder_classifier.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yg0NF2GxZK-4"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Entrenamiento y evaluación del clasificador\n",
        "\n",
        "a. Entrena el clasificador **decoder_classifier** definido en la fase previa utilizando como input la representación codificada del training set obtenida en el paso previo y como output los labels originales del conjunto de training.\n",
        "\n",
        "b. Calcula la pérdida de validación del modelo, utilizando la representación codificada de los datos de validación y como ouput los labels originales del conjunto de validación.\n"
      ],
      "metadata": {
        "id": "LALau4YR6MXz"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dfyaKfN42W7U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "c. Genera predicciones con el modelo clasificador, utiliza el conjunto de test codificado modelo encoder. Guárdalo en la variable pred.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "hapDlY5xTL8-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Obtener las etiquetas con el clasificador\n",
        "#pred = \n",
        "# print(pred)\n",
        "\n",
        "# Convertimos las predicciones a una lista de etiquetas única\n",
        "pred_classes = np.argmax(pred, axis=1)\n",
        "print(pred_classes)\n"
      ],
      "metadata": {
        "id": "EVbIsCaB-_OR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "d. Evalúa las predicciones del modelo y obten la matriz de confusión."
      ],
      "metadata": {
        "id": "DIP23LYiR7an"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
        "\n",
        "cm=confusion_matrix(y_test_labels.argmax(axis=1), pred.argmax(axis=1))\n",
        "print(\"Classification Report:\\n\")\n",
        "cr=classification_report(y_test_labels.argmax(axis=1), pred.argmax(axis=1), target_names=class_names)\n",
        "print(cr)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cnhIsKSW8MA4",
        "outputId": "abed3888-79df-4dd6-ff8c-1b176177e286"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    airplane       0.54      0.56      0.55       296\n",
            "  automobile       0.50      0.64      0.56       311\n",
            "        bird       0.41      0.27      0.32       299\n",
            "         cat       0.33      0.35      0.34       302\n",
            "        deer       0.51      0.28      0.37       278\n",
            "         dog       0.45      0.31      0.37       293\n",
            "        frog       0.55      0.57      0.56       302\n",
            "       horse       0.58      0.53      0.55       298\n",
            "        ship       0.59      0.68      0.64       314\n",
            "       truck       0.43      0.65      0.51       307\n",
            "\n",
            "    accuracy                           0.49      3000\n",
            "   macro avg       0.49      0.48      0.48      3000\n",
            "weighted avg       0.49      0.49      0.48      3000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5. Mejoras a los modelos\n",
        "\n",
        "Aplicando los conceptos del curso modifica dichas redes para obtener un mejor accuracy ¿Crees poder lograr un 70% o tal vez 80% de accuracy con tu modelo? OJO: NO está permitido modificar el modelo clasificador. \n",
        "\n",
        "a.    Experimenta agregando capas, modificando operaciones y modificando las dimensiones de las capas actuales. OJO: Recuerda que para que tu modelo encoder-decoder siga funcionando y puedas reconstruir las imágenes codificadas, las capas de MaxPool del encoder deben de corresponder a las capas UpSample del decoder. Tip: ¿Las capas de pooling ayudan o perjudican a tu modelo?\n",
        " \n",
        "b.    En una celda de texto, justifica los cambios realizados, a la arquitectura.\n",
        " \n",
        "c.     Genera la matriz de confusión de tu ensamble de modelos mejorado. Recuerda que debes re-entrenar el clasificador si la arquitectura del autoencoder cambia. \n"
      ],
      "metadata": {
        "id": "SNfnSotBaTit"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EKhhpQjW-yyr"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": [],
      "authorship_tag": "ABX9TyPG4yPGwNjRTG/98LEE6Gpa",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}