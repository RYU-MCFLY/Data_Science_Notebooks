{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Entrenamiento con Keras_MINIST.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tozanni/Data_Science_Notebooks/blob/main/DL2_Entrenamiento_con_Keras_MINIST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ejemplo: clasificador de imágenes usando Keras\n",
        "\n",
        "Para ilustrar la manera en que Keras es usado en el aprendizaje profundo, realizaremos un ejemplo de clasificación usando conjunto de datos *Fashion MNIST* el cual consta de 70,000 imágenes (las imágenes representan artículos de moda) en escala de grises de 28 × 28 píxeles cada una y con 10 clases. \n",
        "\n",
        "### Uso de Keras para cargar el conjunto de datos\n",
        "\n",
        "Comencemos cargando el conjunto de datos Fashion MNIST. Keras tiene una serie de funciones para cargar conjuntos de datos populares en keras.datasets. El conjunto de datos ya está dividido entre un conjunto de entrenamiento y un conjunto de prueba, pero puede ser útil dividir aún más el conjunto de entrenamiento para tener un conjunto de validación:\n",
        "\n"
      ],
      "metadata": {
        "id": "rT45FhRI-ECW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt \n",
        "import seaborn as sns; sns.set()"
      ],
      "metadata": {
        "id": "htEDMx2Z7umY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l3_3qvt-6L1M"
      },
      "outputs": [],
      "source": [
        "from keras.datasets import fashion_mnist"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fashion_mnist = keras.datasets.fashion_mnist\n",
        "(X_train_full, y_train_full), (X_test, y_test) = fashion_mnist.load_data()"
      ],
      "metadata": {
        "id": "gHpMLo1A7qBI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "El conjunto de entrenamiento contiene 60,000 imágenes en escala de grises, cada una de 28x28 píxeles:"
      ],
      "metadata": {
        "id": "HXiHf4Mm-SbY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_full.dtype"
      ],
      "metadata": {
        "id": "ypaAIoQj-Rl3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ahora dividamos el conjunto de datos de entrenamiento en un conjunto de validación y un conjunto de entrenamiento (más pequeño). También escalamos las intensidades de píxeles en el rango 0-1 y las convertimos en flotantes al dividiéndolas por 255."
      ],
      "metadata": {
        "id": "HzFEF6tt-a8v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_valid, X_train = X_train_full[:5000] / 255., X_train_full[5000:] / 255.\n",
        "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]\n",
        "X_test = X_test / 255"
      ],
      "metadata": {
        "id": "MYecqx5u-YS4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "visualizar una imagen del conjunto de training"
      ],
      "metadata": {
        "id": "xYGFd4bVSA-Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(X_train[0], cmap=\"binary\")\n",
        "plt.axis('off');"
      ],
      "metadata": {
        "id": "mjcl_4Rb-yhl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Las etiquetas van de 0 a 9, por lo que hay 10 tipos diferentes de ropa"
      ],
      "metadata": {
        "id": "HbSEo50_SMej"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class_names = [\"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\",\n",
        "               \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"]"
      ],
      "metadata": {
        "id": "uLc07QaA-2D8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "visualicemos ahora algunas de las imágenes de los datos de entrenamiento con su respectiva etiqueta"
      ],
      "metadata": {
        "id": "IB39NAPg-8X1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig , ax =  plt.subplots(3,10, figsize=(15,5))\n",
        "for i , ax in enumerate(ax.flat):\n",
        "  ax.imshow(X_train[i], cmap='binary')\n",
        "  ax.set_axis_off()\n",
        "  ax.set_title(class_names[y_train[i]])"
      ],
      "metadata": {
        "id": "wMbVlnW0-7FY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Modelo de aprendizaje profundo en keras"
      ],
      "metadata": {
        "id": "HWSwj4TX_DYW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "keras.backend.clear_session()\n",
        "\n",
        "model = keras.models.Sequential();\n",
        "model.add(keras.layers.Flatten(input_shape=[28, 28]));\n",
        "model.add(keras.layers.Dense(300, activation=\"relu\"));\n",
        "model.add(keras.layers.Dense(100, activation=\"relu\"));\n",
        "model.add(keras.layers.Dense(10, activation=\"softmax\"));"
      ],
      "metadata": {
        "id": "kK28mXWq_Ct5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Veamos este código línea por línea:\n",
        "* La primera línea crea un modelo secuencial. Este es el tipo más simple de modelo para redes neuronales que están compuestas de una sola pila de capas, conectadas secuencialmente. Esto se llama la API secuencial.\n",
        "\n",
        "* Luego , construimos la primera capa y la agregamos al modelo. Es una capa Flatten cuyo papel es simplemente convertir cada imagen de entrada en un arregle 1D:\n",
        "\n",
        "* Luego, agregamos una capa oculta densa con 300 neuronas la cual utilizará la función de activación ReLU.\n",
        "\n",
        "* Luego, agregamos una segunda capa oculta densa con 100 neuronas, que también utiliza la función de activación ReLU.\n",
        "\n",
        "* Finalmente, agregamos una capa de salida densa con 10 neuronas (una por clase), usando la función de activación softmax (porque las clases son exclusivas).\n",
        "\n",
        "El método `summary()` muestra un resumen de todas las capas del modelo.\n"
      ],
      "metadata": {
        "id": "3q6tnVO7_QbV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "x5v5P1q6_V6u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Compilando el modelo\n",
        "\n",
        "Después de crear un modelo, se debe llamar el método `compile()` para especificar la función de pérdida y el optimizador a utilizar. Opcionalmente, también puede especificar una lista de métricas  para calcular durante el entrenamiento y la evaluación:"
      ],
      "metadata": {
        "id": "1Wtarq-H_atV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='sparse_categorical_crossentropy',\n",
        "              optimizer='sgd', \n",
        "              metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "9U7Mn0pKSkVo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Entrenando y evaluando el modelo\n",
        "\n",
        "Ahora el modelo está listo para ser entrenado. Para esto simplemente necesitamos llamar a su método `fit()`. Le pasamos las características de entrada (X_train) y las clases de destino (y_train), así como la cantidad de épocas para entrenar (o de lo contrario, sería predeterminado a solo 1). También pasamos un conjunto de validación (esto es opcional): Keras medirá la pérdida y las métricas adicionales en este conjunto al final de cada época, lo cual es muy útil para ver qué tan bien se desempeña realmente el modelo."
      ],
      "metadata": {
        "id": "b01c4I16_pP4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history =  model.fit(X_train, y_train, epochs=5, validation_data=(X_valid, y_valid))"
      ],
      "metadata": {
        "id": "LmBXk31D_Z7Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "La red neuronal está entrenada. En cada época durante el entrenamiento, Keras muestra el número de instancias procesadas hasta el momento (junto con una barra de progreso), el tiempo medio de entrenamiento, la pérdida (loss) y la precisión (accuracy), ambas calculadas en el conjunto de entrenamiento y el conjunto de validación.\n",
        "\n",
        "El método `fit()` devuelve un objeto \"History\" que contiene los parámetros de entrenamiento (history.params), la lista de épocas por las que pasó (history.epoch) y, lo más importante, un diccionario (history.history) que contiene la pérdida y las métricas adicionales que midió al final de cada época en el conjunto de entrenamiento y en el conjunto de validación (si corresponde). \n",
        "\n"
      ],
      "metadata": {
        "id": "R0X01yJ7AEZQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.DataFrame(history.history)\n",
        "df.head()"
      ],
      "metadata": {
        "id": "Pw4yQedzAL3I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.plot(figsize=(8, 5))"
      ],
      "metadata": {
        "id": "y1X9MdeDAP4X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se puede ver que tanto la precisión de entrenamiento como la de validación aumentan constantemente durante el entrenamiento, mientras que la pérdida de entrenamiento y validación disminuye. Ademas , las curvas de validación están bastante cerca de las curvas de entrenamiento, lo que significa que no hay demasiado sobreajuste(overfitting).\n",
        "\n"
      ],
      "metadata": {
        "id": "pb39ASJKAZyP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "HrtyAmKyAY9y"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}