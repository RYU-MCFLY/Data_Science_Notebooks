{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DL - Actividad integradora_1 (Con soluciones)",
      "provenance": [],
      "collapsed_sections": [
        "p5PAhkSzbkRi",
        "97yJHn9aDN3g"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tozanni/Data_Science_Notebooks/blob/main/DL_Actividad_integradora_1_(Con_soluciones).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p5PAhkSzbkRi"
      },
      "source": [
        "# Evaluación de modelos y funciones de pérdida"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g7pqJJrJd8v8"
      },
      "source": [
        "# Importamos la librería SKLearn que incluye algunos datasets muy conocidos\n",
        "import sklearn as skl\n",
        "import numpy as np\n",
        "import scipy as sc\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Los datos de vivienda de California se centran en modelar la relación existente entre las variables RM (Número medio de habitaciones) y MEDV (Valor medio de la vivienda) de la base de datos California."
      ],
      "metadata": {
        "id": "LV-08ezEaVgk"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cBF-24BkiruX"
      },
      "source": [
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "housing = fetch_california_housing()\n",
        "\n",
        "X = housing.data\n",
        "Y = housing.target\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "97yJHn9aDN3g"
      },
      "source": [
        "## Actividad 1: evaluación de modelos usando la función MSE\n",
        "\n",
        "Ajusta tres modelos sobre los datos de vivienda de California. Puedes utilizar la librería SkLearn. Evalúa los siguientes modelos utilizando la métrica del error medio cuadrático (MSE):\n",
        "\n",
        "1.   [Modelo de regresión lineal múltiple con término de intercepto](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html) con término de intercepto\n",
        "2.   Modelo de regresión lineal múltiple sin término de intercepto (intercept=False)\n",
        "3. [Modelo de Perceptrón Multicapa](https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPRegressor.html#sklearn.neural_network.MLPRegressor)\n",
        "\n",
        "**Tus actividades**\n",
        "\n",
        "1.   Ajusta los modelos de regresión arriba descritos, genera una partición de training y test set.\n",
        "2.   Implementa la función de evaluación o pérdida error medio cuadrático para cada uno de los valores del test set.\n",
        "\n",
        "3. Grafica el ajuste de los modelos vs. los datos reales utilizando matplotlib.\n",
        "\n",
        "4. Valida tus resultados comparando vs. la función mean_squared_error de sklearn\n",
        "\n",
        "5. Comenta tus conclusiones, ¿Qué interpretación de las a sus valores de MSE? ¿Qué modelo escogerias y en base a que?\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(housing.DESCR)\n",
        "#genera una partición de training y test set.\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, random_state=42)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J5u5udftG5qU",
        "outputId": "ec8b757b-4a5a-43dd-ae54-f92697cee6ab"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ".. _california_housing_dataset:\n",
            "\n",
            "California Housing dataset\n",
            "--------------------------\n",
            "\n",
            "**Data Set Characteristics:**\n",
            "\n",
            "    :Number of Instances: 20640\n",
            "\n",
            "    :Number of Attributes: 8 numeric, predictive attributes and the target\n",
            "\n",
            "    :Attribute Information:\n",
            "        - MedInc        median income in block group\n",
            "        - HouseAge      median house age in block group\n",
            "        - AveRooms      average number of rooms per household\n",
            "        - AveBedrms     average number of bedrooms per household\n",
            "        - Population    block group population\n",
            "        - AveOccup      average number of household members\n",
            "        - Latitude      block group latitude\n",
            "        - Longitude     block group longitude\n",
            "\n",
            "    :Missing Attribute Values: None\n",
            "\n",
            "This dataset was obtained from the StatLib repository.\n",
            "https://www.dcc.fc.up.pt/~ltorgo/Regression/cal_housing.html\n",
            "\n",
            "The target variable is the median house value for California districts,\n",
            "expressed in hundreds of thousands of dollars ($100,000).\n",
            "\n",
            "This dataset was derived from the 1990 U.S. census, using one row per census\n",
            "block group. A block group is the smallest geographical unit for which the U.S.\n",
            "Census Bureau publishes sample data (a block group typically has a population\n",
            "of 600 to 3,000 people).\n",
            "\n",
            "An household is a group of people residing within a home. Since the average\n",
            "number of rooms and bedrooms in this dataset are provided per household, these\n",
            "columns may take surpinsingly large values for block groups with few households\n",
            "and many empty houses, such as vacation resorts.\n",
            "\n",
            "It can be downloaded/loaded using the\n",
            ":func:`sklearn.datasets.fetch_california_housing` function.\n",
            "\n",
            ".. topic:: References\n",
            "\n",
            "    - Pace, R. Kelley and Ronald Barry, Sparse Spatial Autoregressions,\n",
            "      Statistics and Probability Letters, 33 (1997) 291-297\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Entrenando modelo para train y test set"
      ],
      "metadata": {
        "id": "CNJrLGBcHN3L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import linear_model\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# COMIENZA TU CÓDIGO AQUÍ #\n",
        "\n",
        "def use_sklearn():\n",
        "  ##Modelo de regresión lineal múltiple con término de intercepto con término de intercepto\n",
        "  model = linear_model.LinearRegression().fit(X_train, y_train)\n",
        "  #Modelo de regresión lineal múltiple sin término de intercepto (intercept=False)\n",
        "  model_2 = linear_model.LinearRegression(fit_intercept=False).fit(X_train, y_train)\n",
        "  model_3=MLPRegressor(random_state=1, max_iter=500).fit(X_train, y_train)\n",
        "\n",
        "  yp = model.predict(X_test)\n",
        "  yp2 =  model_2.predict(X_test)\n",
        "  yp3= model_3.predict(X_test)\n",
        "  \n",
        "  print(\"metricas para el set de test\")\n",
        "  print(\"Modelo 1,mse =\", mean_squared_error(y_test, yp))\n",
        "  print(\"Modelo 2,mse =\", mean_squared_error(y_test, yp2))\n",
        "  print(\"Modelo de Perceptrón Multicapa, mse =\", mean_squared_error(y_test, yp3))\n",
        "  \n",
        "  \n",
        "use_sklearn()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R0jQQIzDJaMG",
        "outputId": "50d98512-69a3-4b74-c5f8-cbe1369c5fdd"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "metricas para el set de test\n",
            "Modelo 1,mse = 0.5411287478470682\n",
            "Modelo 2,mse = 0.6159307296888284\n",
            "Modelo de Perceptrón Multicapa, mse = 0.7480028045550321\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "5.Comenta tus conclusiones, ¿Qué interpretación de las a sus valores de MSE? ¿Qué modelo escogerias y en base a que?\n",
        "\n",
        "R: Escogeria el modelo en el que el MSE es el valor mínimo en set de test o validación, esto significa que los valores predichos y los reales son más similares. En este caso eligiría el modelo 1.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "z_Y5bGZ7Z7Vu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Entropía Cruzada\n",
        "\n",
        "La pérdida de entropía cruzada es una métrica que se utiliza para medir el rendimiento de un modelo de clasificación en el aprendizaje automático. La pérdida (o error) se mide como un número entre 0 y 1.\n",
        "\n",
        "\n",
        "**Tus actividades**\n",
        "\n",
        "1. Implementa la función para calcular la entropía cruzada binaria (BCE) del arreglo q y del arreglo r, en relación a los valores verdaderos. BCE(p,q) vs. BCE(q,r)\n",
        "\n",
        "\n",
        "\n",
        "*   p: Datos verdaderos\n",
        "*   q: Predicción del primer modelo\n",
        "*   r: Predicción del segundo modelo\n",
        "\n",
        "\n",
        "2. Comenta tus conclusiones ¿Qué modelo escogerías y qué interpretación le das a sus valores de entropía cruzada?\n",
        "\n",
        "3. Valida tus resultados comparando con la función [log_loss](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.log_loss.html) de SkLearn o Keras"
      ],
      "metadata": {
        "id": "to-TPZZqjU3C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy import asarray\n",
        "\n",
        "# prepare classification data\n",
        "p = asarray([1, 1, 1, 1, 1, 0, 0, 0, 0, 0]) ##valores verdaderos\n",
        "q = asarray([0.8, 0.9, 0.9, 0.6, 0.8, 0.1, 0.4, 0.2, 0.1, 0.3]) #prediccion modelo 1\n",
        "r = asarray([0.9, 0.9, 0.9, 0.9, 0.8, 0.1, 0.1, 0.2, 0.1, 0.1]) #prediccion modelo 2\n"
      ],
      "metadata": {
        "id": "hG6QOTerZ6r3"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.Implementa la función para calcular la entropía cruzada binaria (BCE) del arreglo q y del arreglo r, en relación a los valores verdaderos. BCE(p,q) vs. BCE(q,r)"
      ],
      "metadata": {
        "id": "PCL4EQmLGw3R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from math import log\n",
        "import numpy as np\n",
        "\n",
        "# Funcion base de entropia cruzada binaria para un par de distribuciones en un punto (esperado y predicho)\n",
        "def binary_cross_entropy(p, q):\n",
        "  return -1*(p[0]*log(q[0])+ p[1]*log(q[1]))\n",
        "\n",
        "#Esta es la funcion que calcula la perdida o loss como promedio\n",
        "#de las perdidas de todos los puntos evaluados en el set.\n",
        "def BCE(p,q):\n",
        "  results = list()\n",
        "  for i in range(len(p)):\n",
        "    # Crear la distribucion esperada y pronosticada\n",
        "    exp = [1.0 - p[i], p[i]]\n",
        "    pred = [1.0 - q[i], q[i]]\n",
        "\n",
        "    #Calcular la entropia cruzada para ambos eventos y guardar el resultado\n",
        "    bce = binary_cross_entropy(exp, pred)\n",
        "    results.append(bce)\n",
        " \n",
        "  #Calcular la entropia cruzada promedio\n",
        "  return np.mean(results)\n",
        "\n",
        "bce1 = BCE(p,q)\n",
        "bce2 = BCE(p,r)\n",
        "\n",
        "print('BCE loss de modelo 1: %.4f' % bce1)\n",
        "print('BCE loss de modelo 2: %.4f' % bce2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-0J7yk6YIwOr",
        "outputId": "10d80da9-f7ff-4a2f-c3b5-6bcd569bec2c"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BCE loss de modelo 1: 0.2469\n",
            "BCE loss de modelo 2: 0.1289\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2.Comenta tus conclusiones ¿Qué modelo escogerías y qué interpretación le das a sus valores de entropía cruzada?**\n",
        "\n",
        "R: Podemos observar que el BCE del modelo 2 es menor que la del modelo 1, un valor más cercano a cero indica mayor similaridad entre la distribución verdadera (y_true) y la estimada (y_hat). Por lo tanto, en este caso eligiría el modelo 2."
      ],
      "metadata": {
        "id": "vaoCf1105u0U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "**3.Valida tus resultados comparando con la función log_loss de SkLearn o Keras**\n",
        "\n",
        "Podemos corroborar que los valores de la BCE implementados coinciden con la implementación de BCE de SkLearn."
      ],
      "metadata": {
        "id": "-qA-GxyvGuNP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import log_loss\n",
        "#g_loss(y_true, y_pred,\n",
        "print(log_loss(p,q))#\n",
        "print(log_loss(p,r))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M3Cs0ishF6Qb",
        "outputId": "e1bc0831-8afc-4923-aed6-cd724c25be4c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.24691989080446483\n",
            "0.12891712278910297\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "PavugOCBYZCZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}